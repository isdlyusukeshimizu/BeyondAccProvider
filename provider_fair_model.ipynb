{"cells":[{"cell_type":"markdown","metadata":{"id":"fvyNDFQm8Tr5"},"source":["## Install packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14673,"status":"ok","timestamp":1673276153784,"user":{"displayName":"Saeed Rahmani","userId":"08643326845606389307"},"user_tz":0},"id":"VnNvYkBmRz-F","outputId":"ca974467-a866-48dd-de1a-29f1c979dada"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mip\n","  Downloading mip-1.15.0-py3-none-any.whl (15.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi==1.15.* in /usr/local/lib/python3.8/dist-packages (from mip) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi==1.15.*->mip) (2.21)\n","Installing collected packages: mip\n","Successfully installed mip-1.15.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cornac\n","  Downloading cornac-1.14.2-cp38-cp38-manylinux1_x86_64.whl (14.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.8/dist-packages (from cornac) (4.64.1)\n","Collecting powerlaw\n","  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from cornac) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from cornac) (1.7.3)\n","Requirement already satisfied: mpmath in /usr/local/lib/python3.8/dist-packages (from powerlaw->cornac) (1.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from powerlaw->cornac) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->powerlaw->cornac) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->powerlaw->cornac) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->powerlaw->cornac) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->powerlaw->cornac) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->powerlaw->cornac) (1.15.0)\n","Installing collected packages: powerlaw, cornac\n","Successfully installed cornac-1.14.2 powerlaw-1.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fastdist\n","  Downloading fastdist-1.1.4-py3-none-any.whl (12 kB)\n","Installing collected packages: fastdist\n","Successfully installed fastdist-1.1.4\n"]}],"source":["# Install MIP and Gurobipy for optimization purpose\n","! pip install mip\n","# ! python -m pip install gurobipy==9.1.2\n","# install Cornac framework for RecSys\n","! pip install cornac\n","! pip install fastdist"]},{"cell_type":"markdown","metadata":{"id":"4gT5oYyYy-X8"},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3KNp45j7IGM"},"outputs":[],"source":["# import packages\n","import os\n","import numpy as np\n","from collections import defaultdict\n","from tqdm import tqdm\n","import itertools\n","from itertools import product\n","\n","# from surprise import KNNBasic\n","from fastdist import fastdist\n","\n","from sys import stdout as out\n","from mip import Model, xsum, maximize, BINARY\n","import pandas as pd\n","import scipy.sparse as sp\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","import cornac\n","from cornac.eval_methods import BaseMethod, RatioSplit\n","from cornac.models import MostPop, UserKNN, ItemKNN, MF, PMF, BPR, NeuMF, WMF, HPF, CVAE, VAECF, NMF\n","from cornac.metrics import Precision, Recall, NDCG, AUC, MAP, FMeasure, MRR\n","from cornac.data import Reader\n","from cornac.utils import cache"]},{"cell_type":"markdown","metadata":{"id":"jYlI50GuyV8l"},"source":["## Download datasets, user, and item groups"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWIh5ZiT7NwE"},"outputs":[],"source":["# download datasets: train, test, tune\n","def download_dataset():\n","  ds_root_path = \"datasets/\"\n","  for dataset in ds_names:\n","    dataset_path = os.path.join(ds_root_path, dataset)\n","\n","    if not os.path.isdir(dataset_path):\n","      os.makedirs(dataset_path)\n","      print(\"Directory '%s' is created.\" % dataset_path)\n","    else:\n","      print(\"Directory '%s' is exist.\" % dataset_path)\n","\n","    # -nc: skip downloads that would download to existing files.\n","\n","    try:\n","      os.system(f\"wget -P {dataset_path} -nc https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/{dataset}_train.txt\")\n","      os.system(f\"wget -P {dataset_path} -nc https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/{dataset}_test.txt\")\n","      os.system(f\"wget -P {dataset_path} -nc https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/{dataset}_tune.txt\")\n","      print(f\"{dataset}: The train, tune, and test sets downloaded.\")\n","    except Expception as e:\n","      print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjL34huY7f_I"},"outputs":[],"source":["# dowanload user groups: active and inactive\n","def download_user_groups():\n","  user_root_path = \"user_groups/\"\n","  for dataset in ds_names:\n","    for ugroup in ds_users:\n","      user_groups_path = os.path.join(user_root_path, dataset, ugroup)\n","\n","      if not os.path.isdir(user_groups_path):\n","        os.makedirs(user_groups_path)\n","        print(\"Directory '%s' is created.\" % user_groups_path)\n","      else:\n","        print(\"Directory '%s' is exist.\" % user_groups_path)\n","\n","      # -nc: skip downloads that would download to existing files.\n","\n","      try:\n","        os.system(f\"wget -P {user_groups_path} https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/groups/users/{ugroup}/active_ids.txt\")\n","        os.system(f\"wget -P {user_groups_path} https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/groups/users/{ugroup}/inactive_ids.txt\")\n","        print(f\"{dataset}: User groups on '{ugroup}' downloaded.\")\n","      except Exception as e:\n","        print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDwRmOSjJHKK"},"outputs":[],"source":["# dowanload item groups: short-head and long-tail\n","def download_item_groups():\n","  item_root_path = \"item_groups/\"\n","  for dataset in ds_names:\n","    for igroup in ds_items:\n","      item_groups_path = os.path.join(item_root_path, dataset, igroup)\n","\n","      if not os.path.isdir(item_groups_path):\n","        os.makedirs(item_groups_path)\n","        print(\"Directory '%s' is created.\" % item_groups_path)\n","      else:\n","        print(\"Directory '%s' is exist.\" % item_groups_path)\n","      \n","      # -nc: skip downloads that would download to existing files.\n","    try:\n","      os.system(f\"wget -P {item_groups_path} -nc https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/groups/items/{igroup}/shorthead_items.txt\")\n","      os.system(f\"wget -P {item_groups_path} -nc https://raw.githubusercontent.com/rahmanidashti/CPFairRecSys/main/datasets/{dataset}/groups/items/{igroup}/longtail_items.txt\")\n","      print(f\"{dataset}: Item groups on '{igroup}' downloaded.\")\n","    except Exception as e:\n","      print(e)"]},{"cell_type":"markdown","metadata":{"id":"1OEbK4PzX9ul"},"source":["## Run Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xGcL4Gm7KhT"},"outputs":[],"source":["# dataset congfig\n","ds_names = [\"Gowalla\"]\n","ds_users = ['005']\n","ds_items = ['020']\n","\n","###\n","no_user_groups = 2\n","no_item_groups = 2\n","topk = 50 # this is not a length of recommendation ist, it is only the first topk items for the optimisation\n","top_n = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2318,"status":"ok","timestamp":1673276176542,"user":{"displayName":"Saeed Rahmani","userId":"08643326845606389307"},"user_tz":0},"id":"UVGAHeGSl7Gc","outputId":"da185b71-c651-4f34-e077-25cb3e5bafd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Directory 'datasets/Gowalla' is created.\n","Gowalla: The train, tune, and test sets downloaded.\n","Directory 'user_groups/Gowalla/005' is created.\n","Gowalla: User groups on '005' downloaded.\n","Directory 'item_groups/Gowalla/020' is created.\n","Gowalla: Item groups on '020' downloaded.\n"]}],"source":["download_dataset()\n","download_user_groups()\n","download_item_groups()"]},{"cell_type":"markdown","metadata":{"id":"iVnSrbN9ygDF"},"source":["## Load `Cornac` data and model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcckaEz-7SQr"},"outputs":[],"source":["# reading the train, test, and val sets\n","def read_data(dataset):\n","  \"\"\"\n","  Read the train, test, and tune file using Cornac reader class\n","\n","  Parameters\n","  ----------\n","  dataset : the name of the dataset\n","    example: 'MovieLens100K'\n","\n","  Returns\n","  ----------\n","  train_data:\n","    The train set that is 70% of interactions\n","  tune_data:\n","    The tune set that is 10% of interactions\n","  test_data:\n","    The test set that is 20% of interactions\n","  \"\"\"\n","  reader = Reader()\n","  train_data = reader.read(fpath=f\"datasets/{dataset}/{dataset}_train.txt\", fmt='UIR', sep='\\t')\n","  tune_data = reader.read(fpath=f\"datasets/{dataset}/{dataset}_tune.txt\", fmt='UIR', sep='\\t')\n","  test_data = reader.read(fpath=f\"datasets/{dataset}/{dataset}_test.txt\", fmt='UIR', sep='\\t')\n","  return train_data, tune_data, test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxijedzS7VHq"},"outputs":[],"source":["# load data into Cornac evaluation method\n","def load_data(train_data, test_data):\n","  \"\"\"\n","  load data into Cornac evaluation method\n","\n","  Parameters\n","  ----------\n","  train_data: \n","    train_data from Reader Class\n","  test_data:\n","    test_data from Reader Class\n","\n","  Returns\n","  ----------\n","  eval_method:\n","    Instantiation of a Base evaluation method using the provided train and test sets\n","  \"\"\"\n","  # exclude_unknowns (bool, default: False) – Whether to exclude unknown users/items in evaluation.\n","  # Instantiate a Base evaluation method using the provided train and test sets\n","  eval_method = BaseMethod.from_splits(\n","      train_data=train_data, test_data=test_data, rating_threshold=1.0, exclude_unknowns=True, verbose=True\n","  )\n","\n","  return eval_method"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","id":"gtOdLiJ67XiZ"},"outputs":[],"source":["# running the cornac\n","def run_model(eval_method):\n","  \"\"\"\n","  running the cornac\n","\n","  Parameters\n","  ----------\n","  eval_method: \n","    Cornac's evaluation protocol\n","\n","  Returns\n","  ----------\n","  exp:\n","    Cornac's Experiment\n","  \"\"\"\n","  \n","  models = [\n","            # MostPop(),\n","            # UserKNN(k=20, similarity=\"cosine\", weighting=\"bm25\", name=\"UserKNN-BM25\"),\n","            # ItemKNN(k=20, similarity=\"cosine\", name=\"ItemKNN-Cosine\"),\n","            # BPR(k=50, max_iter=200, learning_rate=0.001, lambda_reg=0.001, verbose=True),\n","            # WMF(k=50, max_iter=50, learning_rate=0.001, lambda_u=0.01, lambda_v=0.01, verbose=True, seed=123),\n","            # HPF(k=50, seed=123, hierarchical=False, name=\"PF\"),\n","            VAECF(k=10, autoencoder_structure=[20], act_fn=\"tanh\", likelihood=\"mult\", n_epochs=100, batch_size=100, learning_rate=0.001, beta=1.0, seed=123, use_gpu=True, verbose=True),\n","            # NeuMF(num_factors=9, layers=[32, 16, 8], act_fn=\"tanh\", num_epochs=5, num_neg=3, batch_size=256, lr=0.001, seed=42, verbose=True)\n","            ]\n","\n","  # define metrics to evaluate the models\n","  metrics = [\n","            AUC(), MAP(), MRR(), NDCG(k=10), Recall(k=10)\n","            # Precision(k=5), Precision(k=10), Precision(k=20),  Precision(k=50), \n","            # Recall(k=5), Recall(k=10), Recall(k=20), Recall(k=50),\n","            # FMeasure(k=5), FMeasure(k=10), FMeasure(k=20), FMeasure(k=50), \n","            # NDCG(k=5), NDCG(k=10), NDCG(k=20), NDCG(k=50)\n","            ]\n","\n","  # put it together in an experiment, voilà!\n","  exp = cornac.Experiment(eval_method=eval_method, models=models, metrics=metrics)\n","  exp.run()\n","\n","  return exp"]},{"cell_type":"markdown","metadata":{"id":"xKk0B-6wzEhj"},"source":["## Load user and item groups"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmAJmsuu9nIY"},"outputs":[],"source":["# Create a set of IDs for each users group\n","# Creat a matrix U which shows the user and the groups of the user\n","def read_user_groups(user_group_fpath: str, gid) -> set:\n","  \"\"\"\n","  Read the user groups lists\n","\n","  Parameters\n","  ----------\n","  user_group_fpath:\n","    The path of the user group file\n","\n","  U (global variabvle):\n","    The global matrix of users and their group\n","\n","  Returns\n","  ----------\n","  user_ids:\n","    The set of user ids corresponding to the group\n","  \"\"\"\n","\n","  user_group = open(user_group_fpath, 'r').readlines()\n","  user_ids = set()\n","  for eachline in user_group:\n","    uid = eachline.strip()\n","    # convert uids to uidx\n","    uid = eval_method.train_set.uid_map[uid]\n","    uid = int(uid)\n","    user_ids.add(uid)\n","    U[uid][gid] = 1\n","  return user_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQIgU-RFN9a0"},"outputs":[],"source":["# read test data\n","def read_ground_truth(test_file):\n","  \"\"\"\n","  Read test set data\n","\n","  Parameters\n","  ----------\n","  test_file:\n","    The test set data\n","\n","  Returns\n","  ----------\n","  ground_truth:\n","    A dictionary includes user with actual items in test data\n","  \"\"\"\n","  ground_truth = defaultdict(set)\n","  truth_data = open(test_file, 'r').readlines()\n","  for eachline in truth_data:\n","    uid, iid, _ = eachline.strip().split()\n","\n","    # convert uids to uidx\n","    uid = eval_method.train_set.uid_map[uid]\n","    # convert iids to iidx\n","    iid = eval_method.train_set.iid_map[iid]\n","\n","    uid, iid = int(uid), int(iid)\n","    ground_truth[uid].add(iid)\n","  return ground_truth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YuxZe64gNejy"},"outputs":[],"source":["# read train data\n","def read_train_data(train_file):\n","  \"\"\"\n","  Read test set data\n","\n","  Parameters\n","  ----------\n","  train_file:\n","    The train_file set data\n","\n","  Returns\n","  ----------\n","  train_checkins:\n","    A dictionary includes user with items in train data\n","  pop: dictionary\n","    A dictionary of all items alongside of its occurrences counter in the training data\n","    example: {1198: 893, 1270: 876, 593: 876, 2762: 867}\n","  \"\"\"\n","  train_checkins = defaultdict(set)\n","  item_training_matrix = np.zeros((eval_method.total_items, eval_method.total_users))\n","  pop_items = dict()\n","  train_data = open(train_file, 'r').readlines()\n","\n","  for eachline in train_data:\n","    uid, iid, _ = eachline.strip().split()\n","\n","    # convert uids to uidx\n","    uid = eval_method.train_set.uid_map[uid]\n","    # convert iids to iidx\n","    iid = eval_method.train_set.iid_map[iid]\n","\n","    uid, iid = int(uid), int(iid)\n","    item_training_matrix[iid, uid] = 1.0\n","    # a dictionary of popularity of items\n","    if iid in pop_items.keys():\n","      pop_items[iid] += 1\n","    else:\n","      pop_items[iid] = 1\n","    train_checkins[uid].add(iid)\n","\n","  zero_indices = np.where(~item_training_matrix.any(axis=1))[0]\n","  for zero_index in zero_indices:\n","    item_training_matrix[zero_index, 0] = 0.0000001\n","\n","  return train_checkins, pop_items, item_training_matrix"]},{"cell_type":"markdown","metadata":{"id":"3vU5YS_gv6SO"},"source":["## Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uI3kZR7Bn4EJ"},"outputs":[],"source":["def catalog_coverage(predicted: list, catalog: list) -> float:\n","  \"\"\"\n","  Computes the catalog coverage for k lists of recommendations\n","  Parameters\n","  ----------\n","  predicted : a list of lists\n","      Ordered predictions\n","      example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n","  catalog: list\n","      A list of all unique items in the training data\n","      example: ['A', 'B', 'C', 'X', 'Y', Z]\n","  k: integer\n","      The number of observed recommendation lists\n","      which randomly choosed in our offline setup\n","  Returns\n","  ----------\n","  catalog_coverage:\n","      The catalog coverage of the recommendations as a percent rounded to 2 decimal places\n","  ----------\n","  Metric Defintion:\n","  Ge, M., Delgado-Battenfeld, C., & Jannach, D. (2010, September).\n","  Beyond accuracy: evaluating recommender systems by coverage and serendipity.\n","  In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). ACM.\n","  \"\"\"\n","  predicted_flattened = [p for sublist in predicted for p in sublist]\n","  L_predictions = len(set(predicted_flattened))\n","  catalog_coverage = round(L_predictions / (len(catalog) * 1.0) * 100, 2)\n","  # output: precent (%)\n","  return catalog_coverage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T451FOM3m4qx"},"outputs":[],"source":["def novelty(predicted: list, pop: dict, u: int, k: int) -> float:\n","  \"\"\"\n","  Computes the novelty for a list of recommended items for a user\n","  Parameters\n","  ----------\n","  predicted : a list of recommedned items\n","      Ordered predictions\n","      example: ['X', 'Y', 'Z']\n","  pop: dictionary\n","      A dictionary of all items alongside of its occurrences counter in the training data\n","      example: {1198: 893, 1270: 876, 593: 876, 2762: 867}\n","  u: integer\n","      The number of users in the training data\n","  k: integer\n","      The length of recommended lists per user\n","  Returns\n","  ----------\n","  novelty:\n","      The novelty of the recommendations in system level\n","  mean_self_information:\n","      The novelty of the recommendations in recommended top-N list level\n","  ----------\n","  Metric Defintion:\n","  Zhou, T., Kuscsik, Z., Liu, J. G., Medo, M., Wakeling, J. R., & Zhang, Y. C. (2010).\n","  Solving the apparent diversity-accuracy dilemma of recommender systems.\n","  Proceedings of the National Academy of Sciences, 107(10), 4511-4515.\n","  \"\"\"\n","  self_information = 0\n","  for item in predicted:\n","    if item in pop.keys():\n","      item_popularity = pop[item] / u\n","      item_novelty_value = np.sum(-np.log2(item_popularity))\n","    else:\n","      item_novelty_value = 0\n","    self_information += item_novelty_value\n","  novelty_score = self_information / k\n","  return novelty_score"]},{"cell_type":"code","source":["def personalization(predicted: list) -> float:\n","    \"\"\"\n","    Personalization measures recommendation similarity across users.\n","    A high score indicates good personalization (user's lists of recommendations are different).\n","    A low score indicates poor personalization (user's lists of recommendations are very similar).\n","    A model is \"personalizing\" well if the set of recommendations for each user is different.\n","    Parameters:\n","    ----------\n","    predicted : a list of lists\n","        Ordered predictions\n","        example: [['X', 'Y', 'Z'], ['X', 'Y', 'Z']]\n","    Returns:\n","    -------\n","        The personalization score for all recommendations.\n","    \"\"\"\n","\n","    def make_rec_matrix(predicted: list) -> sp.csr_matrix:\n","        df = pd.DataFrame(data=predicted).reset_index().melt(\n","            id_vars='index', value_name='item',\n","        )\n","        df = df[['index', 'item']].pivot(index='index', columns='item', values='item')\n","        df = pd.notna(df)*1\n","        rec_matrix = sp.csr_matrix(df.values)\n","        return rec_matrix\n","\n","    # create matrix for recommendations\n","    predicted = np.array(predicted)\n","    rec_matrix_sparse = make_rec_matrix(predicted)\n","\n","    # calculate similarity for every user's recommendation list\n","    similarity = cosine_similarity(X=rec_matrix_sparse, dense_output=False)\n","\n","    # get indicies for upper right triangle w/o diagonal\n","    upper_right = np.triu_indices(similarity.shape[0], k=1)\n","\n","    # calculate average similarity\n","    personalization = np.mean(similarity[upper_right])\n","\n","    return 1 - personalization"],"metadata":{"id":"xcRZSyW3VXsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def item_KNN_similarity(training_set):\n","    # Compute similarty matrix between items so we can measure diversity\n","    sim_options = {'name': 'cosine', 'user_based': False}\n","    simsAlgo = KNNBasic(sim_options=sim_options)\n","    simsAlgo.fit(training_set)\n","\n","    print(simsAlgo)\n","\n","\n","def item_cosine_similarty(item_feature_matrix):\n","    print(\"Start items Similarity Matrix computing ...\")\n","    item_similarity_matrix = fastdist.matrix_to_matrix_distance(item_feature_matrix,\n","                                                                item_feature_matrix,\n","                                                                fastdist.cosine,\n","                                                                \"cosine\")\n","\n","    # np.save('cosine_item_sim_Gowalla_min.npy', item_similarity_matrix)\n","    print(\"Items Similarity Matrix computed.\")\n","    return item_similarity_matrix"],"metadata":{"id":"lLYKF54oeFsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unserendipity(actual, predicted):\n","  # H_u: actual_u, a set of items existing in user records\n","  # R_uN: predicted, N top recommendations\n","  norm_sim = 0\n","  for itemID1 in actual:\n","    for itemID2 in predicted:\n","      norm_sim = norm_sim + items_sim_matrix[int(itemID1), int(itemID2)] / top_n\n","  \n","  norm_sim = norm_sim / (eval_method.total_users * len(actual))\n","\n","  return norm_sim"],"metadata":{"id":"JY9dNkRQ9UN1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def listDiversity(predicted: list):\n","    \"\"\"\n","    Computes the diversity for a list of recommended items for a user\n","\n","    Parameters\n","    ----------\n","    predicted: list\n","        A list of predicted numeric/character vectors of retrieved documents for the corresponding element of actual\n","        example: ['X', 'Y', 'Z']\n","\n","    Returns\n","    ----------\n","        diversity\n","    \"\"\"\n","    pairCount = 0\n","    similarity = 0\n","    pairs = itertools.combinations(predicted, 2)\n","    for pair in pairs:\n","        itemID1 = pair[0]\n","        itemID2 = pair[1]\n","        similarity += items_sim_matrix[int(itemID1), int(itemID2)]\n","        pairCount += 1\n","    averageSimilarity = similarity / pairCount\n","    diversity = 1 - averageSimilarity\n","    return diversity"],"metadata":{"id":"CqTvM7M1c_p5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Accuracy"],"metadata":{"id":"HeKkeFNdNGQv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7Ymn9W4Qdht"},"outputs":[],"source":["def precisionk(actual, predicted):\n","  return 1.0 * len(set(actual) & set(predicted)) / len(predicted)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WR8y_5vrKKaw"},"outputs":[],"source":["def recallk(actual, predicted):\n","  return 1.0 * len(set(actual) & set(predicted)) / len(actual)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTs77lfzLMBx"},"outputs":[],"source":["def ndcgk(actual, predicted):\n","  idcg = 1.0\n","  dcg = 1.0 if predicted[0] in actual else 0.0\n","  for i, p in enumerate(predicted[1:]):\n","    if p in actual:\n","      dcg += 1.0 / np.log(i+2)\n","    idcg += 1.0 / np.log(i+2)\n","  return dcg / idcg"]},{"cell_type":"markdown","metadata":{"id":"TbchhQqfwEBg"},"source":["## Load User and Item Matrices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YBJA3fayetN"},"outputs":[],"source":["# Here we saved the results of scores and you can read them from repo to do your experiments.\n","# S is a matrix to store user's scores on each item\n","# P incldues the indecies of topk ranked items \n","# Sprime saves the scores of topk ranked items\n","\n","def load_ranking_matrices(model, total_users, total_items, topk):\n","  S = np.zeros((total_users, total_items))\n","  P = np.zeros((total_users, topk))\n","\n","  # for model in exp.models:\n","  print(model.name)\n","  for uid in tqdm(range(total_users)):\n","    S[uid] = model.score(uid)\n","    P[uid] = np.array(list(reversed(model.score(uid).argsort()))[:topk])\n","\n","  return S, P"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6purGS8lSc0W"},"outputs":[],"source":["# Ahelp is a binary matrix in which an element of its is 1 if the corresponding element in P (which is an item index) is in ground truth.\n","# Actually is shows whether the rankied item in P is included in ground truth or not.\n","\n","def load_ground_truth_index(total_users, topk, P, train_checkins):\n","  Ahelp = np.zeros((total_users, topk))\n","  for uid in tqdm(range(total_users)):\n","    for j in range(topk):\n","      # convert user_ids to user_idx\n","      # convert item_ids to item_idx\n","      if P[uid][j] in train_checkins[uid]:\n","        Ahelp[uid][j] = 1\n","  return Ahelp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuOUY4lCJ57A"},"outputs":[],"source":["# create a set of IDs for each users group\n","def read_item_groups(item_group_fpath: str, gid) -> set:\n","  item_group = open(item_group_fpath, 'r').readlines()\n","  item_ids = set()\n","  for eachline in item_group:\n","    iid = eachline.strip()\n","    # convert iids to iidx\n","    iid = eval_method.train_set.iid_map[iid]\n","    iid = int(iid)\n","    item_ids.add(iid)\n","    I[iid][gid] = 1\n","  return item_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRlw5kZLPzQ4"},"outputs":[],"source":["def read_item_index(total_users, topk, no_item_groups):\n","  Ihelp = np.zeros((total_users, topk, no_item_groups))\n","  for uid in range(total_users):\n","    for lid in range(topk):\n","      # convert item_ids to item_idx\n","      if P[uid][lid] in shorthead_item_ids:\n","        Ihelp[uid][lid][0] = 1\n","      elif P[uid][lid] in longtail_item_ids:\n","        Ihelp[uid][lid][1] = 1\n","  return Ihelp"]},{"cell_type":"markdown","metadata":{"id":"kkl6XrhAwQG2"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48cabQBvwPMN"},"outputs":[],"source":["def metric_per_group(group, W):\n","  NDCG10 = list()\n","  Pre10 = list()\n","  Rec10 = list()\n","  Novelty10 = list()\n","  Diversity10 = list()\n","  UnSerendipity10 = list()\n","  predicted = list()\n","  All_Predicted = list()\n","\n","  for uid in tqdm(group):\n","    if uid in ground_truth.keys():\n","      for j in range(50):\n","        if W[uid][j].x == 1:\n","          predicted.append(P[uid][j])\n","      copy_predicted = predicted[:]\n","      All_Predicted.append(copy_predicted)\n","      NDCG = ndcgk(actual=ground_truth[uid], predicted=predicted)\n","      Pre = precisionk(actual=ground_truth[uid], predicted=predicted)\n","      Rec = recallk(actual=ground_truth[uid], predicted=predicted)\n","      Novelty = novelty(predicted=predicted, pop=pop_items, u=eval_method.total_users, k=10)\n","      Diversity = listDiversity(predicted=predicted)\n","      UnSerendipity = unserendipity(actual=ground_truth[uid], predicted=predicted)\n","\n","      NDCG10.append(NDCG)\n","      Pre10.append(Pre)\n","      Rec10.append(Rec)\n","      Novelty10.append(Novelty)\n","      Diversity10.append(Diversity)\n","      UnSerendipity10.append(UnSerendipity)\n","\n","      # cleaning the predicted list for a new user\n","      predicted.clear()\n","\n","  catalog = catalog_coverage(predicted=All_Predicted, catalog=pop_items.keys())\n","  personalizing = personalization(predicted=All_Predicted)\n","  return round(np.mean(NDCG10), 5), round(np.mean(Pre10), 5), round(np.mean(Rec10), 5), round(np.mean(Novelty10), 5), round(np.mean(Diversity10), 5), catalog, round(personalizing, 5), round(sum(UnSerendipity10), 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JorbXFzomfmv"},"outputs":[],"source":["def metric_on_all(W):\n","  \"\"\"\n","  \"\"\"\n","  predicted_user = list()\n","  NDCG_all = list()\n","  PRE_all = list()\n","  REC_all = list()\n","  Novelty_all = list()\n","  ListDiversity_all = list()\n","  UnSerendipity_all = list()\n","  All_Predicted = list()\n","\n","\n","  for uid in tqdm(range(eval_method.total_users)):\n","    if uid in ground_truth.keys():\n","      for j in range(50):\n","        if W[uid][j].x == 1:\n","          predicted_user.append(P[uid][j])\n","\n","      copy_predicted = predicted_user[:]\n","      All_Predicted.append(copy_predicted)\n","\n","      NDCG_user = ndcgk(actual=ground_truth[uid], predicted=predicted_user)\n","      PRE_user = precisionk(actual=ground_truth[uid], predicted=predicted_user)\n","      REC_user = recallk(actual=ground_truth[uid], predicted=predicted_user)\n","      Novelty_user = novelty(predicted=predicted_user, pop=pop_items, u=eval_method.total_users, k=10)\n","      ListDiversity_user = listDiversity(predicted=predicted_user)\n","      UnSerendipity_user = unserendipity(actual=ground_truth[uid], predicted=predicted_user)\n","\n","      NDCG_all.append(NDCG_user)\n","      PRE_all.append(PRE_user)\n","      REC_all.append(REC_user)\n","      Novelty_all.append(Novelty_user)\n","      ListDiversity_all.append(ListDiversity_user)\n","      UnSerendipity_all.append(UnSerendipity_user)\n","\n","      # cleaning the predicted list for a new user\n","      predicted_user.clear()\n","\n","  catalog = catalog_coverage(predicted=All_Predicted, catalog=pop_items.keys())\n","  personalizing = personalization(predicted=All_Predicted)\n","  return round(np.mean(NDCG_all), 5), round(np.mean(PRE_all), 5), round(np.mean(REC_all), 5), round(np.mean(Novelty_all), 5), round(np.mean(ListDiversity_all), 5), catalog, round(personalizing, 5), round(sum(UnSerendipity_all), 5)"]},{"cell_type":"code","source":["def relevant_short_long_items(W):\n","  # list of recommended items to a user\n","  predicted_user = list()\n","  actual_user = []\n","  actual_recommedned = []\n","  recommedned_item_groups = [0 , 0]\n","  for uid in tqdm(range(eval_method.total_users)):\n","    if uid in ground_truth.keys():\n","      for j in range(50):\n","        if W[uid][j].x == 1:\n","          predicted_user.append(P[uid][j])\n","      actual_user = ground_truth[uid]\n","      actual_recommedned = set(actual_user) & set(predicted_user)\n","      for actual_rec_item in actual_recommedned:\n","        if actual_rec_item in shorthead_item_ids:\n","          recommedned_item_groups[0] += 1\n","        elif actual_rec_item in longtail_item_ids:\n","          recommedned_item_groups[1] += 1\n","  return recommedned_item_groups"],"metadata":{"id":"RVSzB0E2k7Q0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PSBVs9wiwXGF"},"source":["## Fairness"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ERUinxWfALw"},"outputs":[],"source":["def fairness_optimisation(fairness='N', uepsilon=0.000005, iepsilon = 0.0000005):\n","  print(f\"Runing fairness optimisation on '{fairness}', {format(uepsilon, 'f')}, {format(iepsilon, 'f')}\")\n","  # V1: No. of users\n","  # V2: No. of top items (topk)\n","  # V3: No. of user groups\n","  # V4: no. og item groups\n","  V1, V2, V3, V4 = set(range(eval_method.total_users)), set(range(topk)), set(range(no_user_groups)), set(range(no_item_groups))\n","\n","  # initiate model\n","  model = Model()\n","\n","  # W is a matrix (size: user * top items) to be learned by model\n","  #W = [[model.add_var(var_type=BINARY) for j in V2] for i in V1]\n","  W = [[model.add_var() for j in V2] for i in V1]\n","  user_dcg = [model.add_var() for i in V1] \n","  user_ndcg = [model.add_var() for i in V1] \n","  group_ndcg_v = [model.add_var() for k in V3]\n","  item_group = [model.add_var() for k in V4]\n","\n","  user_precision=[model.add_var() for i in V1] \n","  group_precision=[model.add_var() for k in V3]\n","\n","  user_recall=[model.add_var() for i in V1] \n","  group_recall= [model.add_var() for k in V3]\n","\n","  if fairness == 'N':\n","    ### No Fairness ###\n","    model.objective = maximize(xsum((S[i][j] * W[i][j]) for i in V1 for j in V2))\n","  elif fairness == 'C':\n","    ### C-Fairness: NDCG_Best: group_ndcg_v[1] - group_ndcg_v[0] ###\n","    model.objective = maximize(xsum((S[i][j] * W[i][j]) for i in V1 for j in V2) - uepsilon * (group_ndcg_v[1] - group_ndcg_v[0]))\n","  elif fairness == 'P':\n","    model.objective = maximize(xsum((S[i][j] * W[i][j]) for i in V1 for j in V2) - iepsilon * (item_group[0] - item_group[1]))\n","  elif fairness == 'CP':\n","    model.objective = maximize(xsum((S[i][j] * W[i][j]) for i in V1 for j in V2) - uepsilon * (group_ndcg_v[1] - group_ndcg_v[0]) - iepsilon * (item_group[0] - item_group[1]))\n","\n","  # first constraint: the number of 1 in W should be equal to top-k, recommending top-k best items\n","  k = 10\n","  for i in V1:\n","      model += xsum(W[i][j] for j in V2) == k\n","\n","  for i in V1:\n","    user_idcg_i = 7.137938133620551\n","      \n","    model += user_dcg[i] == xsum((W[i][j] * Ahelp[i][j]) for j in V2) \n","    model += user_ndcg[i] == user_dcg[i] / user_idcg_i\n","    \n","    model += user_precision[i]==xsum((W[i][j] * Ahelp[i][j]) for j in V2) / k\n","    model += user_recall[i]==xsum((W[i][j] * Ahelp[i][j]) for j in V2) / len(train_checkins[i])\n","\n","  for k in V3:\n","    model += group_ndcg_v[k] == xsum(user_dcg[i] * U[i][k] for i in V1)\n","    model += group_precision[k] == xsum(user_precision[i] * U[i][k] for i in V1)\n","    model += group_recall[k] == xsum(user_recall[i] * U[i][k] for i in V1)\n","\n","  for k in V4:\n","    model += item_group[k] == xsum(W[i][j] * Ihelp[i][j][k] for i in V1 for j in V2)\n","\n","  item_group_ids = [[], []]\n","\n","  for i in V1:\n","    for j in V2:\n","      model += W[i][j] <= 1\n","  # optimizing\n","  model.optimize()\n","\n","  return W, item_group"]},{"cell_type":"markdown","metadata":{"id":"Z9NhMbgRyIXg"},"source":["## Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPtl1pdcG7i8"},"outputs":[],"source":["def write_results():\n","  ndcg_ac, pre_ac, rec_ac, novelty_ac, diversity_ac, coverage_ac, personalizing_ac, unserendipity_ac = metric_per_group(group=active_user_ids, W=W)\n","  ndcg_iac, pre_iac, rec_iac, novelty_iac, diversity_iac, coverage_iac, personalizing_iac, unserendipity_iac = metric_per_group(group=inactive_user_ids, W=W)\n","  ndcg_all, pre_all, rec_all, novelty_all, diversity_all, coverage_all, personalizing_all, unserendipity_all = metric_on_all(W=W)\n","  rel_short_items, rel_long_items = relevant_short_long_items(W)\n","  if fair_mode == 'N':\n","    results.write(f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},-,-,{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{diversity_all},{diversity_ac},{diversity_iac},{coverage_all},{coverage_ac},{coverage_iac},{personalizing_all},{personalizing_ac},{personalizing_iac},{unserendipity_all},{unserendipity_ac},{unserendipity_iac},{item_group[0].x},{rel_short_items},{item_group[1].x},{rel_long_items},{eval_method.total_users * 10}=={item_group[0].x + item_group[1].x}\") \n","  elif fair_mode == 'C':\n","    results.write(f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},{format(user_eps, '.7f')},-,{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{diversity_all},{diversity_ac},{diversity_iac},{coverage_all},{coverage_ac},{coverage_iac},{personalizing_all},{personalizing_ac},{personalizing_iac},{unserendipity_all},{unserendipity_ac},{unserendipity_iac},{item_group[0].x},{rel_short_items},{item_group[1].x},{rel_long_items},{eval_method.total_users * 10}=={item_group[0].x + item_group[1].x}\") \n","  elif fair_mode == 'P':\n","    results.write(f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},-,{format(item_eps, '.7f')},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{diversity_all},{diversity_ac},{diversity_iac},{coverage_all},{coverage_ac},{coverage_iac},{personalizing_all},{personalizing_ac},{personalizing_iac},{unserendipity_all},{unserendipity_ac},{unserendipity_iac},{item_group[0].x},{rel_short_items},{item_group[1].x},{rel_long_items},{eval_method.total_users * 10}=={item_group[0].x + item_group[1].x}\") \n","  elif fair_mode == 'CP':\n","    results.write(f\"{dataset},{model.name},{u_group}%,{i_group}%,{fair_mode},{format(user_eps, '.7f')},{format(item_eps, '.7f')},{ndcg_all},{ndcg_ac},{ndcg_iac},{pre_all},{pre_ac},{pre_iac},{rec_all},{rec_ac},{rec_iac},{novelty_all},{novelty_ac},{novelty_iac},{diversity_all},{diversity_ac},{diversity_iac},{coverage_all},{coverage_ac},{coverage_iac},{personalizing_all},{personalizing_ac},{personalizing_iac},{unserendipity_all},{unserendipity_ac},{unserendipity_iac},{item_group[0].x},{rel_short_items},{item_group[1].x},{rel_long_items},{eval_method.total_users * 10}=={item_group[0].x + item_group[1].x}\") \n","  results.write('\\n')"]},{"cell_type":"code","source":["# items_sim_matrix[0,50]"],"metadata":{"id":"iGgw1Z9clUpc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e7049acb3faa4083a865b6525d296b77","9a4058f3c33f40898fc72ca992492e25","11459c1cc6ef4de4af59f5932a4d8ae4","5deb01e494ab4533acf0786875a46691","96be096d569f452b83122c2ea943077d","0def82ab8ce04188b68653ebdb200bd0","4e8f63c4147f48ae87b278d408e55f06","342ebd2fe5c54501a5b8a54777464215","f6b0a3b3754c4d96a40e586d83e06a2f","9e9072a613ac4b6ea3eea1cbac3edefc","9d4dec57c40f4998899f590e8dfa3259","0d83b86185fb4ab5ae50b87f5fa6f48c","acf17e7f79e74d81a4f7e82205d6418e","9584a3cd5add427d8a995c2aefefb156","155069da784c434aae3c0e05c959092d","b469c5af939e4e0db656ba2da7c2a7d8","e3d06b27aab9462383d025cd59827822","40444c169b184116b5c8d387288bdc88","ba64de607dc44857a4ee20706f29f906","8fd10ed72b2140c4917aa40cfe91f099","f3cbe2970c1a4789a8ef82e55ded7d9f","c81b8eb85ade4bc1838487c85da4926e"]},"id":"jXev5h4_XGbf","executionInfo":{"status":"ok","timestamp":1673277081391,"user_tz":0,"elapsed":50071,"user":{"displayName":"Saeed Rahmani","userId":"08643326845606389307"}},"outputId":"682f8d78-d9ca-40d6-f135-dffa066ec749"},"outputs":[{"output_type":"stream","name":"stdout","text":["Datasets: Gowalla\n","rating_threshold = 1.0\n","exclude_unknowns = True\n","---\n","Training data:\n","Number of users = 1130\n","Number of items = 1189\n","Number of ratings = 46371\n","Max rating = 215.0\n","Min rating = 1.0\n","Global mean = 1.8\n","---\n","Test data:\n","Number of users = 1130\n","Number of items = 1188\n","Number of ratings = 13249\n","Number of unknown users = 0\n","Number of unknown items = 0\n","---\n","Total users = 1130\n","Total items = 1189\n","Start items Similarity Matrix computing ...\n","Items Similarity Matrix computed.\n","\n","[VAECF] Training started!\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7049acb3faa4083a865b6525d296b77"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","[VAECF] Evaluation started!\n"]},{"output_type":"display_data","data":{"text/plain":["Ranking:   0%|          | 0/1130 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d83b86185fb4ab5ae50b87f5fa6f48c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","TEST:\n","...\n","      |    AUC |    MAP |    MRR | NDCG@10 | Recall@10 | Train (s) | Test (s)\n","----- + ------ + ------ + ------ + ------- + --------- + --------- + --------\n","VAECF | 0.8454 | 0.0898 | 0.2695 |  0.1115 |    0.0965 |   11.4186 |   2.1635\n","\n","ActiveU: 56, InActive: 1074, All: 1130\n","No. of Shorthead Items: 238 and No. of Longtaill Items: 951\n","> Model: VAECF\n","VAECF\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1130/1130 [00:01<00:00, 783.88it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 35682.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Runing fairness optimisation on 'N', 0.000005, 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 56/56 [00:00<00:00, 1958.89it/s]\n","100%|██████████| 1074/1074 [00:00<00:00, 3434.01it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3218.43it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3139.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Runing fairness optimisation on 'P', 0.000005, 0.003000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 56/56 [00:00<00:00, 1999.31it/s]\n","100%|██████████| 1074/1074 [00:00<00:00, 3071.03it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3417.26it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3109.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Runing fairness optimisation on 'P', 0.000005, 0.000500\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 56/56 [00:00<00:00, 1909.38it/s]\n","100%|██████████| 1074/1074 [00:00<00:00, 3238.31it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3400.85it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3024.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Runing fairness optimisation on 'P', 0.000005, 0.000100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 56/56 [00:00<00:00, 1614.85it/s]\n","100%|██████████| 1074/1074 [00:00<00:00, 3421.53it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3011.32it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3035.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Runing fairness optimisation on 'P', 0.000005, 0.000050\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 56/56 [00:00<00:00, 1629.88it/s]\n","100%|██████████| 1074/1074 [00:00<00:00, 3259.83it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3365.18it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3241.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Runing fairness optimisation on 'P', 0.000005, 0.000005\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 56/56 [00:00<00:00, 1904.08it/s]\n","100%|██████████| 1074/1074 [00:00<00:00, 3233.04it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3335.20it/s]\n","100%|██████████| 1130/1130 [00:00<00:00, 3108.30it/s]\n"]}],"source":["# 1: Iterate over the datasets\n","for dataset in ds_names:\n","  print(f\"Datasets: {dataset}\")\n","  # read train, tune, test datasets\n","  train_data, tune_data, test_data = read_data(dataset=dataset)\n","  # load data into Cornac and create eval_method\n","  eval_method = load_data(train_data=train_data, test_data=test_data)\n","  total_users = eval_method.total_users\n","  total_items = eval_method.total_items\n","  # load train_checkins and pop_items dictionary\n","  train_checkins, pop_items, item_training_matrix = read_train_data(train_file = f\"datasets/{dataset}/{dataset}_train.txt\")\n","  items_sim_matrix = item_cosine_similarty(item_feature_matrix=item_training_matrix)\n","  # load ground truth dict\n","  ground_truth = read_ground_truth(test_file = f\"datasets/{dataset}/{dataset}_test.txt\")\n","  # run Cornac models and create experiment object including models' results\n","  exp = run_model(eval_method=eval_method)\n","  # 4: read user groups\n","  for u_group in ds_users:\n","    # read matrix U for users and their groups\n","    U = np.zeros((total_users, no_user_groups))\n","    # load active and inactive users\n","    active_user_ids = read_user_groups(user_group_fpath = f\"user_groups/{dataset}/{u_group}/active_ids.txt\", gid = 0)\n","    inactive_user_ids = read_user_groups(user_group_fpath = f\"user_groups/{dataset}/{u_group}/inactive_ids.txt\", gid = 1)\n","    print(f\"ActiveU: {len(active_user_ids)}, InActive: {len(inactive_user_ids)}, All: {len(active_user_ids) + len(inactive_user_ids)}\")\n","    len_sizes = [len(active_user_ids), len(inactive_user_ids)]\n","    # 5: read item groups\n","    for i_group in ds_items:\n","      # read matrix I for items and their groups\n","      I = np.zeros((total_items, no_item_groups))\n","      # read item groups\n","      shorthead_item_ids = read_item_groups(item_group_fpath = f\"item_groups/{dataset}/{i_group}/shorthead_items.txt\", gid = 0)\n","      longtail_item_ids = read_item_groups(item_group_fpath = f\"item_groups/{dataset}/{i_group}/longtail_items.txt\", gid = 1)\n","      print(f\"No. of Shorthead Items: {len(shorthead_item_ids)} and No. of Longtaill Items: {len(longtail_item_ids)}\")\n","      # 2: iterate over the models\n","      for model in exp.models:\n","        results = open(f\"results_{dataset}_{model.name}.csv\", 'w')\n","        results.write(\"Dataset,Model,GUser,GItem,Type,User_EPS,Item_EPS,ndcg_ALL,ndcg_ACT,ndcg_INACT,Pre_ALL,Pre_ACT,Pre_INACT,Rec_ALL,Rec_ACT,Rec_INACT,Nov_ALL,Nov_ACT,Nov_INACT,Div_ALL,Div_ACT,Div_INACT,Cov_ALL,Cov_ACT,Cov_INACT,Per_ALL,Per_ACT,Per_INACT,UnSer_all,UnSer_ac,UnSer_iac,Short_Items,Rel_Short,Long_Items,Rel_Long,All_Items\\n\")\n","        print(f\"> Model: {model.name}\")\n","        # load matrix S and P\n","        S, P = load_ranking_matrices(model=model, total_users=total_users, total_items=total_items, topk=topk)\n","        # load matrix Ahelp\n","        Ahelp = load_ground_truth_index(total_users=total_users, topk=topk, P=P, train_checkins=train_checkins)\n","        # load matrix Ihelp\n","        Ihelp = read_item_index(total_users=total_users, topk=50, no_item_groups=no_item_groups)\n","        # iterate on fairness mode: user, item, user-item\n","        for fair_mode in ['N', 'P']:\n","          if fair_mode == 'N':\n","            W, item_group = fairness_optimisation(fairness=fair_mode)\n","            write_results()\n","          elif fair_mode == 'C':\n","            for user_eps in [0.003, 0.0005, 0.0001, 0.00005, 0.000005]:\n","              W, item_group = fairness_optimisation(fairness=fair_mode, uepsilon=user_eps)\n","              write_results()\n","          elif fair_mode == 'P':\n","            for item_eps in [0.003, 0.0005, 0.0001, 0.00005, 0.000005]:\n","              W, item_group = fairness_optimisation(fairness=fair_mode, iepsilon=item_eps)\n","              write_results()\n","          elif fair_mode == 'CP':\n","            for user_eps in [0.003, 0.0005, 0.0001, 0.00005, 0.000005]:\n","              for item_eps in [0.003, 0.0005, 0.0001, 0.00005, 0.000005]:\n","                W, item_group = fairness_optimisation(fairness=fair_mode, uepsilon=user_eps, iepsilon=item_eps)\n","                write_results()\n","        results.close()"]},{"cell_type":"code","source":[],"metadata":{"id":"zryWsvScYZhb"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["TbchhQqfwEBg"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e7049acb3faa4083a865b6525d296b77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a4058f3c33f40898fc72ca992492e25","IPY_MODEL_11459c1cc6ef4de4af59f5932a4d8ae4","IPY_MODEL_5deb01e494ab4533acf0786875a46691"],"layout":"IPY_MODEL_96be096d569f452b83122c2ea943077d"}},"9a4058f3c33f40898fc72ca992492e25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0def82ab8ce04188b68653ebdb200bd0","placeholder":"​","style":"IPY_MODEL_4e8f63c4147f48ae87b278d408e55f06","value":"100%"}},"11459c1cc6ef4de4af59f5932a4d8ae4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_342ebd2fe5c54501a5b8a54777464215","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6b0a3b3754c4d96a40e586d83e06a2f","value":100}},"5deb01e494ab4533acf0786875a46691":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e9072a613ac4b6ea3eea1cbac3edefc","placeholder":"​","style":"IPY_MODEL_9d4dec57c40f4998899f590e8dfa3259","value":" 100/100 [00:11&lt;00:00,  9.37it/s, loss=2.63]"}},"96be096d569f452b83122c2ea943077d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0def82ab8ce04188b68653ebdb200bd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e8f63c4147f48ae87b278d408e55f06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"342ebd2fe5c54501a5b8a54777464215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6b0a3b3754c4d96a40e586d83e06a2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e9072a613ac4b6ea3eea1cbac3edefc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4dec57c40f4998899f590e8dfa3259":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d83b86185fb4ab5ae50b87f5fa6f48c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acf17e7f79e74d81a4f7e82205d6418e","IPY_MODEL_9584a3cd5add427d8a995c2aefefb156","IPY_MODEL_155069da784c434aae3c0e05c959092d"],"layout":"IPY_MODEL_b469c5af939e4e0db656ba2da7c2a7d8"}},"acf17e7f79e74d81a4f7e82205d6418e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3d06b27aab9462383d025cd59827822","placeholder":"​","style":"IPY_MODEL_40444c169b184116b5c8d387288bdc88","value":"Ranking: 100%"}},"9584a3cd5add427d8a995c2aefefb156":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba64de607dc44857a4ee20706f29f906","max":1130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8fd10ed72b2140c4917aa40cfe91f099","value":1130}},"155069da784c434aae3c0e05c959092d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3cbe2970c1a4789a8ef82e55ded7d9f","placeholder":"​","style":"IPY_MODEL_c81b8eb85ade4bc1838487c85da4926e","value":" 1130/1130 [00:02&lt;00:00, 563.63it/s]"}},"b469c5af939e4e0db656ba2da7c2a7d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3d06b27aab9462383d025cd59827822":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40444c169b184116b5c8d387288bdc88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba64de607dc44857a4ee20706f29f906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fd10ed72b2140c4917aa40cfe91f099":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3cbe2970c1a4789a8ef82e55ded7d9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c81b8eb85ade4bc1838487c85da4926e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}